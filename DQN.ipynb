{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import retro\n",
    "from gym import Env\n",
    "from gym.spaces import MultiBinary, Box, Discrete\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StreetFighter(Env):\n",
    "    def __init__(self,game_state='Champion.Level1.RyuVsGuile.state',record=False):\n",
    "        super().__init__()\n",
    "        self.observation_space = Box(low=0,high=255,shape=(84,84,1), dtype=np.uint8)\n",
    "        self.action_space = Discrete(2**12)\n",
    "        self.total_matches_won = 0\n",
    "        self.total_enemy_matches_won = 0\n",
    "        self.prev_matches_won = 0\n",
    "        self.prev_enemy_matches_won = 0\n",
    "        self.record = record\n",
    "        # if record:\n",
    "        #     self.game = retro.make(game='StreetFighterII-Champion', record='.',state=game_state,use_restricted_actions=retro.Actions.DISCRETE)\n",
    "        # else:\n",
    "        self.game = retro.make(game='StreetFighterII-Champion', state=game_state,use_restricted_actions=retro.Actions.DISCRETE)\n",
    "\n",
    "\n",
    "    def step(self, action):\n",
    "        obs, reward, done, info = self.game.step(action)\n",
    "        obs_orig = obs\n",
    "        obs = self.preprocess(obs)\n",
    "        frame_delta = obs - self.previous_frame\n",
    "        self.previous_frame = obs\n",
    "        if self.prev_matches_won > info['matches_won']:\n",
    "            self.prev_matches_won = info['matches_won']\n",
    "        if self.prev_enemy_matches_won > info['enemy_matches_won']:\n",
    "            self.prev_enemy_matches_won = info['enemy_matches_won']\n",
    "        self.total_matches_won = self.total_matches_won + info['matches_won'] - self.prev_matches_won\n",
    "        self.total_enemy_matches_won = self.total_enemy_matches_won + info['enemy_matches_won'] - self.prev_enemy_matches_won\n",
    "        self.prev_matches_won = info['matches_won']\n",
    "        self.prev_enemy_matches_won = info['enemy_matches_won']\n",
    "        reward = info['score'] - self.score\n",
    "        self.score = info['score']\n",
    "        self.obs_orig = obs_orig\n",
    "        return frame_delta, reward, done, info\n",
    "        \n",
    "    def get_obs_orig(self):\n",
    "        return self.obs_orig\n",
    "\n",
    "    def render(self,*args,**kwargs):\n",
    "        self.game.render()\n",
    "\n",
    "    def reset(self):\n",
    "        obs = self.game.reset()\n",
    "        obs = self.preprocess(obs)\n",
    "        self.previous_frame = obs\n",
    "        self.score = 0\n",
    "        self.prev_matches_won = 0\n",
    "        self.prev_enemy_matches_won = 0\n",
    "        return obs\n",
    "\n",
    "    def preprocess(self, observation):\n",
    "        gray = cv2.cvtColor(observation, cv2.COLOR_BGR2GRAY)\n",
    "        resize = cv2.resize(gray, (84,84), cv2.INTER_CUBIC)\n",
    "        channels = np.reshape(resize, (84,84,1))\n",
    "        return channels\n",
    "\n",
    "    def close(self):\n",
    "        self.game.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = StreetFighter(game_state='Champion.Level1.Chun-LiVsDhalsim.state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\reece\\anaconda3\\envs\\streetfighter37_copy3\\lib\\site-packages\\pyglet\\image\\codecs\\wic.py:289: UserWarning: [WinError -2147417850] Cannot change thread mode after it is set\n",
      "  warnings.warn(str(err))\n"
     ]
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "action = env.action_space.sample()\n",
    "while True:\n",
    "    state, reward, done, info = env.step(action)\n",
    "    # if reward != 0:\n",
    "    #     print(reward)\n",
    "    #     print(info)\n",
    "    env.render()\n",
    "    if done:\n",
    "        break\n",
    "    action = env.action_space.sample()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\reece\\anaconda3\\envs\\streetfighter37_copy3\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import os\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecFrameStack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_DIR = './logs/DQN/Chun-Li'\n",
    "OPT_DIR = './opt/DQN/Chun-Li'\n",
    "CHECKPOINT_DIR = './train/DQN/Chun-Li'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(trial):\n",
    "    return {\n",
    "        'learning_rate':trial.suggest_loguniform('learning_rate',1e-5,1e-4),\n",
    "        'gamma':trial.suggest_loguniform('gamma', 0.8,0.9999),\n",
    "        'tau':trial.suggest_loguniform('tau', 0.001,0.01),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_agent(trial):\n",
    "    try:\n",
    "        model_params = optimize(trial)\n",
    "        env = StreetFighter(game_state='Champion.Level1.Chun-LiVsDhalsim.state')\n",
    "        env = Monitor(env,LOG_DIR)\n",
    "        env = DummyVecEnv([lambda: env])\n",
    "        env = VecFrameStack(env,4,channels_order='last')\n",
    "\n",
    "        model = DQN(\"CnnPolicy\",env,tensorboard_log=LOG_DIR,verbose=0,batch_size=256,buffer_size=80000, **model_params) # cnn policy uses conv neural net for \n",
    "        model.learn(total_timesteps=10000)\n",
    "\n",
    "        mean_reward, _ = evaluate_policy(model,env,n_eval_episodes=10)\n",
    "        env.close()\n",
    "        \n",
    "        SAVE_PATH = os.path.join(OPT_DIR, 'trial_{}_best_model'.format(trial.number))\n",
    "        model.save(SAVE_PATH)\n",
    "        print(mean_reward)\n",
    "        \n",
    "        return mean_reward\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return -1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 00:47:46,353] A new study created in memory with name: no-name-c48c3e99-cabc-4c69-a4ca-7aa6e9db8402\n",
      "c:\\Users\\reece\\anaconda3\\envs\\streetfighter37_copy3\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "c:\\Users\\reece\\anaconda3\\envs\\streetfighter37_copy3\\lib\\site-packages\\ipykernel_launcher.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  after removing the cwd from sys.path.\n",
      "c:\\Users\\reece\\anaconda3\\envs\\streetfighter37_copy3\\lib\\site-packages\\ipykernel_launcher.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"\"\"\n",
      "c:\\Users\\reece\\anaconda3\\envs\\streetfighter37_copy3\\lib\\site-packages\\stable_baselines3\\common\\save_util.py:276: UserWarning: Path 'opt\\DQN\\Chun-Li' does not exist. Will create it.\n",
      "  warnings.warn(f\"Path '{path.parent}' does not exist. Will create it.\")\n",
      "[I 2024-04-25 00:55:38,105] Trial 0 finished with value: 25800.0 and parameters: {'learning_rate': 3.0252410059117312e-05, 'gamma': 0.9482323632497901, 'tau': 0.004839968390490763}. Best is trial 0 with value: 25800.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25800.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 01:03:18,192] Trial 1 finished with value: 14300.0 and parameters: {'learning_rate': 2.4451880911973988e-05, 'gamma': 0.8196584178937547, 'tau': 0.005184327332132177}. Best is trial 0 with value: 25800.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14300.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 01:09:06,909] Trial 2 finished with value: 5000.0 and parameters: {'learning_rate': 2.4188270943251677e-05, 'gamma': 0.9387053205851688, 'tau': 0.004077530947446545}. Best is trial 0 with value: 25800.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 01:18:25,370] Trial 3 finished with value: 37700.0 and parameters: {'learning_rate': 1.6687767968147328e-05, 'gamma': 0.9006227850493569, 'tau': 0.004357598835318333}. Best is trial 3 with value: 37700.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37700.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 01:25:28,786] Trial 4 finished with value: 10500.0 and parameters: {'learning_rate': 2.3547555244747854e-05, 'gamma': 0.9723085348778504, 'tau': 0.002009424983738764}. Best is trial 3 with value: 37700.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10500.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 01:29:07,083] Trial 5 finished with value: 2900.0 and parameters: {'learning_rate': 6.962667543717265e-05, 'gamma': 0.8379968344178078, 'tau': 0.0014708653621579295}. Best is trial 3 with value: 37700.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2900.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 01:39:33,033] Trial 6 finished with value: 23200.0 and parameters: {'learning_rate': 3.4680664060177655e-05, 'gamma': 0.8990402541027979, 'tau': 0.00981471716203836}. Best is trial 3 with value: 37700.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 01:49:29,283] Trial 7 finished with value: 19300.0 and parameters: {'learning_rate': 7.712777331150607e-05, 'gamma': 0.8367263730159661, 'tau': 0.003464971855927796}. Best is trial 3 with value: 37700.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19300.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 01:59:40,859] Trial 8 finished with value: 33000.0 and parameters: {'learning_rate': 1.3005758616694313e-05, 'gamma': 0.9756536005843028, 'tau': 0.001546442436689417}. Best is trial 3 with value: 37700.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-25 02:10:28,642] Trial 9 finished with value: 28000.0 and parameters: {'learning_rate': 7.831093685676595e-05, 'gamma': 0.8344501332737503, 'tau': 0.0010387106141507203}. Best is trial 3 with value: 37700.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28000.0\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(optimize_agent,n_trials=10,n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenTrial(number=3, state=TrialState.COMPLETE, values=[37700.0], datetime_start=datetime.datetime(2024, 4, 25, 1, 9, 6, 910912), datetime_complete=datetime.datetime(2024, 4, 25, 1, 18, 25, 370178), params={'learning_rate': 1.6687767968147328e-05, 'gamma': 0.9006227850493569, 'tau': 0.004357598835318333}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'learning_rate': FloatDistribution(high=0.0001, log=True, low=1e-05, step=None), 'gamma': FloatDistribution(high=0.9999, log=True, low=0.8, step=None), 'tau': FloatDistribution(high=0.01, log=True, low=0.001, step=None)}, trial_id=3, value=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 1.6687767968147328e-05,\n",
       " 'gamma': 0.9006227850493569,\n",
       " 'tau': 0.004357598835318333}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.callbacks import BaseCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainAndLoggingCallback(BaseCallback):\n",
    "    def __init__(self, check_freq, save_path, verbose=1):\n",
    "        super(TrainAndLoggingCallback,self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def _init_callback(self):\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            model_path = os.path.join(self.save_path, 'best_model_{}_'.format(self.n_calls))\n",
    "            self.model.save(model_path)\n",
    "            self.logger.record('matches_won', self.training_env.get_attr('total_matches_won')[0])\n",
    "            self.logger.record('enemy_matches_won', self.training_env.get_attr('total_enemy_matches_won')[0])\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = TrainAndLoggingCallback(check_freq=10000,save_path=CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = StreetFighter(game_state='Champion.Level1.Chun-LiVsDhalsim.state')\n",
    "env = Monitor(env,LOG_DIR)\n",
    "env = DummyVecEnv([lambda: env])\n",
    "env = VecFrameStack(env,4,channels_order='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {}\n",
    "model_params['learning_rate'] = 1.6687767968147328e-05\n",
    "model_params['gamma'] = 0.9006227850493569\n",
    "model_params['tau'] = 0.004357598835318333"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Logging to ./logs/DQN/Chun-Li\\DQN_11\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 8        |\n",
      "| matches_won         | 6        |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.29e+04 |\n",
      "|    ep_rew_mean      | 1.89e+04 |\n",
      "|    exploration_rate | 0.51     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 302      |\n",
      "|    time_elapsed     | 170      |\n",
      "|    total_timesteps  | 51602    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.67e-05 |\n",
      "|    loss             | 1.95     |\n",
      "|    n_updates        | 400      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 15       |\n",
      "| matches_won         | 10       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.25e+04 |\n",
      "|    ep_rew_mean      | 1.59e+04 |\n",
      "|    exploration_rate | 0.0518   |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 22       |\n",
      "|    time_elapsed     | 4362     |\n",
      "|    total_timesteps  | 99813    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.67e-05 |\n",
      "|    loss             | 9.41e-05 |\n",
      "|    n_updates        | 12453    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 26       |\n",
      "| matches_won         | 11       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.08e+04 |\n",
      "|    ep_rew_mean      | 1.28e+04 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 18       |\n",
      "|    time_elapsed     | 7039     |\n",
      "|    total_timesteps  | 130137   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.67e-05 |\n",
      "|    loss             | 0.000261 |\n",
      "|    n_updates        | 20034    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 33       |\n",
      "| matches_won         | 12       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.03e+04 |\n",
      "|    ep_rew_mean      | 1.14e+04 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 16       |\n",
      "|    time_elapsed     | 10157    |\n",
      "|    total_timesteps  | 165248   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.67e-05 |\n",
      "|    loss             | 0.00169  |\n",
      "|    n_updates        | 28811    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 41       |\n",
      "| matches_won         | 18       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.02e+04 |\n",
      "|    ep_rew_mean      | 1.37e+04 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 13671    |\n",
      "|    total_timesteps  | 204074   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.67e-05 |\n",
      "|    loss             | 1.95     |\n",
      "|    n_updates        | 38518    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 49       |\n",
      "| matches_won         | 23       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.05e+04 |\n",
      "|    ep_rew_mean      | 1.5e+04  |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 18029    |\n",
      "|    total_timesteps  | 252198   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.67e-05 |\n",
      "|    loss             | 3.29     |\n",
      "|    n_updates        | 50549    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 57       |\n",
      "| matches_won         | 26       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.03e+04 |\n",
      "|    ep_rew_mean      | 1.42e+04 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 21417    |\n",
      "|    total_timesteps  | 288889   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.67e-05 |\n",
      "|    loss             | 0.00171  |\n",
      "|    n_updates        | 59722    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 67       |\n",
      "| matches_won         | 30       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.04e+04 |\n",
      "|    ep_rew_mean      | 1.4e+04  |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 25588    |\n",
      "|    total_timesteps  | 334154   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.67e-05 |\n",
      "|    loss             | 1.95     |\n",
      "|    n_updates        | 71038    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 77       |\n",
      "| matches_won         | 36       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.07e+04 |\n",
      "|    ep_rew_mean      | 1.41e+04 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 12       |\n",
      "|    time_elapsed     | 30698    |\n",
      "|    total_timesteps  | 385080   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.67e-05 |\n",
      "|    loss             | 3.95     |\n",
      "|    n_updates        | 83769    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 86       |\n",
      "| matches_won         | 41       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.08e+04 |\n",
      "|    ep_rew_mean      | 1.49e+04 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 12       |\n",
      "|    time_elapsed     | 34034    |\n",
      "|    total_timesteps  | 432271   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.67e-05 |\n",
      "|    loss             | 0.00163  |\n",
      "|    n_updates        | 95567    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 94       |\n",
      "| matches_won         | 47       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.1e+04  |\n",
      "|    ep_rew_mean      | 1.55e+04 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 12       |\n",
      "|    time_elapsed     | 38308    |\n",
      "|    total_timesteps  | 482429   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.67e-05 |\n",
      "|    loss             | 0.000854 |\n",
      "|    n_updates        | 108107   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 102      |\n",
      "| matches_won         | 52       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.1e+04  |\n",
      "|    ep_rew_mean      | 1.55e+04 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 12       |\n",
      "|    time_elapsed     | 42066    |\n",
      "|    total_timesteps  | 528694   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.67e-05 |\n",
      "|    loss             | 34.3     |\n",
      "|    n_updates        | 119673   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 113      |\n",
      "| matches_won         | 59       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.12e+04 |\n",
      "|    ep_rew_mean      | 1.56e+04 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 12       |\n",
      "|    time_elapsed     | 46387    |\n",
      "|    total_timesteps  | 582245   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.67e-05 |\n",
      "|    loss             | 3.9      |\n",
      "|    n_updates        | 133061   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 121      |\n",
      "| matches_won         | 64       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.12e+04 |\n",
      "|    ep_rew_mean      | 1.64e+04 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 12       |\n",
      "|    time_elapsed     | 50972    |\n",
      "|    total_timesteps  | 627647   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.67e-05 |\n",
      "|    loss             | 1.95     |\n",
      "|    n_updates        | 144411   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 131      |\n",
      "| matches_won         | 70       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.12e+04 |\n",
      "|    ep_rew_mean      | 1.65e+04 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 12       |\n",
      "|    time_elapsed     | 54410    |\n",
      "|    total_timesteps  | 673187   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.67e-05 |\n",
      "|    loss             | 0.00145  |\n",
      "|    n_updates        | 155796   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 140      |\n",
      "| matches_won         | 74       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.11e+04 |\n",
      "|    ep_rew_mean      | 1.62e+04 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 12       |\n",
      "|    time_elapsed     | 58487    |\n",
      "|    total_timesteps  | 712461   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.67e-05 |\n",
      "|    loss             | 1.95     |\n",
      "|    n_updates        | 165615   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 150      |\n",
      "| matches_won         | 82       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.14e+04 |\n",
      "|    ep_rew_mean      | 1.65e+04 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 64823    |\n",
      "|    total_timesteps  | 773303   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.67e-05 |\n",
      "|    loss             | 0.000763 |\n",
      "|    n_updates        | 180825   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 158      |\n",
      "| matches_won         | 87       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.14e+04 |\n",
      "|    ep_rew_mean      | 1.65e+04 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 11       |\n",
      "|    time_elapsed     | 68814    |\n",
      "|    total_timesteps  | 823969   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.67e-05 |\n",
      "|    loss             | 0.00189  |\n",
      "|    n_updates        | 193492   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 167      |\n",
      "| matches_won         | 92       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.14e+04 |\n",
      "|    ep_rew_mean      | 1.66e+04 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 12       |\n",
      "|    time_elapsed     | 72072    |\n",
      "|    total_timesteps  | 865329   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.67e-05 |\n",
      "|    loss             | 0.000562 |\n",
      "|    n_updates        | 203832   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 175      |\n",
      "| matches_won         | 97       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.14e+04 |\n",
      "|    ep_rew_mean      | 1.7e+04  |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 12       |\n",
      "|    time_elapsed     | 75318    |\n",
      "|    total_timesteps  | 908454   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.67e-05 |\n",
      "|    loss             | 0.000635 |\n",
      "|    n_updates        | 214613   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 185      |\n",
      "| matches_won         | 101      |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.14e+04 |\n",
      "|    ep_rew_mean      | 1.69e+04 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 12       |\n",
      "|    time_elapsed     | 79033    |\n",
      "|    total_timesteps  | 957089   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.67e-05 |\n",
      "|    loss             | 0.000441 |\n",
      "|    n_updates        | 226772   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.dqn.dqn.DQN at 0x208c828cec8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DQN(\"CnnPolicy\",env,tensorboard_log=LOG_DIR,verbose=2,batch_size=256,buffer_size=80000, **model_params) # cnn policy uses conv neural net for \n",
    "# model.load(os.path.join(OPT_DIR, 'trial_0_best_model.zip'))\n",
    "model.load(os.path.join(OPT_DIR, 'trial_3_best_model.zip'))\n",
    "model.learn(total_timesteps=1000000,callback=callback)\n",
    "# can increase training time and learning rate later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = StreetFighter(game_state='Champion.Level1.Chun-LiVsDhalsim.state')\n",
    "env = Monitor(env,LOG_DIR)\n",
    "env = DummyVecEnv([lambda: env])\n",
    "env = VecFrameStack(env,4,channels_order='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11400.0\n"
     ]
    }
   ],
   "source": [
    "model = DQN.load(os.path.join(CHECKPOINT_DIR, 'best_model_50000_'))\n",
    "# Ken best (steps - reward) 1000000 - 1400,  50000 - 3300\n",
    "# Guile best (steps - reward) 1000000 - 2700, \n",
    "# Zangief best (steps - reward) 1000000 - 18400, 58000 - 10300\n",
    "# Chun-Li best (steps - reward) 1000000 - 23200, 500000 - 16900, 50000 = 11400\n",
    "mean_reward, _ = evaluate_policy(model, env, render=True, n_eval_episodes=5)\n",
    "print(mean_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import animation\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_frames_as_gif(frames, path='./', filename='gym_animation.gif'):\n",
    "\n",
    "    #Mess with this to change frame size\n",
    "    plt.figure(figsize=(frames[0].shape[1] / 72.0, frames[0].shape[0] / 72.0), dpi=72)\n",
    "\n",
    "    patch = plt.imshow(frames[0])\n",
    "    plt.axis('off')\n",
    "\n",
    "    def animate(i):\n",
    "        patch.set_data(frames[i])\n",
    "\n",
    "    anim = animation.FuncAnimation(plt.gcf(), animate, frames = len(frames), interval=50)\n",
    "    anim.save(path + filename, writer='imagemagick', fps=180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'my_env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_51356\\1210699323.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmy_env\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'my_env' is not defined"
     ]
    }
   ],
   "source": [
    "my_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "Exception ignored in: <function SimpleImageViewer.__del__ at 0x00000208BA2491F8>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\reece\\anaconda3\\envs\\streetfighter37_copy3\\lib\\site-packages\\gym\\envs\\classic_control\\rendering.py\", line 458, in __del__\n",
      "    self.close()\n",
      "  File \"c:\\Users\\reece\\anaconda3\\envs\\streetfighter37_copy3\\lib\\site-packages\\gym\\envs\\classic_control\\rendering.py\", line 454, in close\n",
      "    self.window.close()\n",
      "  File \"c:\\Users\\reece\\anaconda3\\envs\\streetfighter37_copy3\\lib\\site-packages\\pyglet\\window\\win32\\__init__.py\", line 313, in close\n",
      "    super(Win32Window, self).close()\n",
      "  File \"c:\\Users\\reece\\anaconda3\\envs\\streetfighter37_copy3\\lib\\site-packages\\pyglet\\window\\__init__.py\", line 838, in close\n",
      "    app.windows.remove(self)\n",
      "  File \"c:\\Users\\reece\\anaconda3\\envs\\streetfighter37_copy3\\lib\\_weakrefset.py\", line 109, in remove\n",
      "    self.data.remove(ref(item))\n",
      "KeyError: (<weakref at 0x0000020881E37C28; to 'Win32Window' at 0x00000208BFE56188>,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANMAAACoCAYAAAB64tvbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAACBElEQVR4nO3ZsQ2EQAwAwb8X/bdsKoCEFQg0kzpxsnLgNTPzAy77P70AfIWYICImiIgJImKCiJggsp0N11p37QGvcfRNcpkgIiaIiAkiYoKImCAiJoiICSJigoiYICImiIgJImKCiJggIiaIiAkiYoKImCAiJoiICSJigoiYICImiIgJImKCiJggIiaIiAkiYoKImCAiJoiICSJigoiYICImiIgJImKCiJggIiaIiAkiYoKImCAiJoiICSJigoiYICImiIgJImKCiJggIiaIiAkiYoKImCAiJoiICSJigoiYICImiIgJImKCiJggIiaIiAkiYoKImCAiJoiICSJigoiYICImiIgJImKCiJggIiaIiAkiYoKImCAiJoiICSJigoiYICImiIgJImKCiJggIiaIiAkiYoKImCAiJoiICSJigoiYICImiIgJImKCiJggIiaIiAkiYoKImCAiJoiICSJigoiYICImiIgJImKCiJggIiaIiAkiYoKImCAiJoiICSJigoiYICImiIgJImKCiJggIiaIiAkiYoKImCAiJoiICSJigoiYICImiIgJImKCiJggIiaIiAkiYoKImCAiJoiICSJigoiYICImiIgJImKCiJggIiaIiAkiYoKImCAiJoiICSJigoiYILKdDWfmrj3g9VwmiIgJImKCiJggIiaIiAkiOy0pC03Pyv2PAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 256x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Ensure you have imagemagick installed with \n",
    "sudo apt-get install imagemagick\n",
    "Open file in CLI with:\n",
    "xgd-open <filelname>\n",
    "\"\"\"\n",
    "\n",
    "#Make gym env\n",
    "my_env = StreetFighter(game_state='Champion.Level1.Chun-LiVsDhalsim.state')\n",
    "env = Monitor(my_env,LOG_DIR)\n",
    "env = DummyVecEnv([lambda: env])\n",
    "env = VecFrameStack(env,4,channels_order='last')\n",
    "\n",
    "model = DQN.load(os.path.join(CHECKPOINT_DIR, 'best_model_1000000_'))\n",
    "obs = env.reset()\n",
    "done = False\n",
    "frames = []\n",
    "\n",
    "while not done:\n",
    "    if done:\n",
    "        break\n",
    "    # frames.append(env.render(mode=\"rgb_array\"))\n",
    "    env.render()\n",
    "    obs,reward,done,info = env.step(model.predict(obs)[0])\n",
    "    rec_obs = my_env.get_obs_orig()\n",
    "    frames.append(rec_obs)\n",
    "env.close()\n",
    "\n",
    "save_frames_as_gif(frames)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "street_fighter37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
