{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import retro\n",
    "from gym import Env\n",
    "from gym.spaces import MultiBinary, Box, Discrete\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StreetFighter(Env):\n",
    "    def __init__(self,game_state='Champion.Level1.KenVsRyu.state',record=False):\n",
    "        super().__init__()\n",
    "        self.observation_space = Box(low=0,high=255,shape=(84,84,1), dtype=np.uint8)\n",
    "        self.action_space = Discrete(2**12)\n",
    "        self.total_matches_won = 0\n",
    "        self.total_enemy_matches_won = 0\n",
    "        self.prev_matches_won = 0\n",
    "        self.prev_enemy_matches_won = 0\n",
    "        self.record = record\n",
    "        # if record:\n",
    "        #     self.game = retro.make(game='StreetFighterII-Champion', record='.',state=game_state,use_restricted_actions=retro.Actions.DISCRETE)\n",
    "        # else:\n",
    "        self.game = retro.make(game='StreetFighterII-Champion', state=game_state,use_restricted_actions=retro.Actions.DISCRETE)\n",
    "\n",
    "\n",
    "    def step(self, action):\n",
    "        obs, reward, done, info = self.game.step(action)\n",
    "        obs_orig = obs\n",
    "        obs = self.preprocess(obs)\n",
    "        frame_delta = obs - self.previous_frame\n",
    "        self.previous_frame = obs\n",
    "        if self.prev_matches_won > info['matches_won']:\n",
    "            self.prev_matches_won = info['matches_won']\n",
    "        if self.prev_enemy_matches_won > info['enemy_matches_won']:\n",
    "            self.prev_enemy_matches_won = info['enemy_matches_won']\n",
    "        self.total_matches_won = self.total_matches_won + info['matches_won'] - self.prev_matches_won\n",
    "        self.total_enemy_matches_won = self.total_enemy_matches_won + info['enemy_matches_won'] - self.prev_enemy_matches_won\n",
    "        self.prev_matches_won = info['matches_won']\n",
    "        self.prev_enemy_matches_won = info['enemy_matches_won']\n",
    "        reward = info['score'] - self.score\n",
    "        self.score = info['score']\n",
    "        self.obs_orig = obs_orig\n",
    "        return frame_delta, reward, done, info\n",
    "        \n",
    "    def get_obs_orig(self):\n",
    "        return self.obs_orig\n",
    "\n",
    "    def render(self,*args,**kwargs):\n",
    "        self.game.render()\n",
    "\n",
    "    def reset(self):\n",
    "        obs = self.game.reset()\n",
    "        obs = self.preprocess(obs)\n",
    "        self.previous_frame = obs\n",
    "        self.score = 0\n",
    "        self.prev_matches_won = 0\n",
    "        self.prev_enemy_matches_won = 0\n",
    "        return obs\n",
    "\n",
    "    def preprocess(self, observation):\n",
    "        gray = cv2.cvtColor(observation, cv2.COLOR_BGR2GRAY)\n",
    "        resize = cv2.resize(gray, (84,84), cv2.INTER_CUBIC)\n",
    "        channels = np.reshape(resize, (84,84,1))\n",
    "        return channels\n",
    "\n",
    "    def close(self):\n",
    "        self.game.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = StreetFighter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\reece\\anaconda3\\envs\\streetfighter37\\lib\\site-packages\\pyglet\\image\\codecs\\wic.py:289: UserWarning: [WinError -2147417850] Cannot change thread mode after it is set\n",
      "  warnings.warn(str(err))\n"
     ]
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "action = env.action_space.sample()\n",
    "while True:\n",
    "    state, reward, done, info = env.step(action)\n",
    "    # if reward != 0:\n",
    "    #     print(reward)\n",
    "    #     print(info)\n",
    "    env.render()\n",
    "    if done:\n",
    "        break\n",
    "    action = env.action_space.sample()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\reece\\anaconda3\\envs\\streetfighter37_copy3\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import os\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecFrameStack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_DIR = './logs/DQN/Ken'\n",
    "OPT_DIR = './opt/DQN/Ken'\n",
    "CHECKPOINT_DIR = './train/DQN/Ken'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(trial):\n",
    "    return {\n",
    "        'learning_rate':trial.suggest_loguniform('learning_rate',1e-5,1e-4),\n",
    "        'gamma':trial.suggest_loguniform('gamma', 0.8,0.9999),\n",
    "        'tau':trial.suggest_loguniform('tau', 0.001,0.01),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_agent(trial):\n",
    "    try:\n",
    "        model_params = optimize(trial)\n",
    "        env = StreetFighter()\n",
    "        env = Monitor(env,LOG_DIR)\n",
    "        env = DummyVecEnv([lambda: env])\n",
    "        env = VecFrameStack(env,4,channels_order='last')\n",
    "\n",
    "        model = DQN(\"CnnPolicy\",env,tensorboard_log=LOG_DIR,verbose=0,batch_size=256,buffer_size=80000, **model_params) # cnn policy uses conv neural net for \n",
    "        model.learn(total_timesteps=10000)\n",
    "\n",
    "        mean_reward, _ = evaluate_policy(model,env,n_eval_episodes=10)\n",
    "        env.close()\n",
    "        \n",
    "        SAVE_PATH = os.path.join(OPT_DIR, 'trial_{}_best_model'.format(trial.number))\n",
    "        model.save(SAVE_PATH)\n",
    "        print(mean_reward)\n",
    "        \n",
    "        return mean_reward\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return -1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-21 11:00:28,609] A new study created in memory with name: no-name-b0b92b46-87b7-4a58-b3ac-bd46bc8a43bf\n",
      "c:\\Users\\reece\\anaconda3\\envs\\streetfighter37_copy3\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "c:\\Users\\reece\\anaconda3\\envs\\streetfighter37_copy3\\lib\\site-packages\\ipykernel_launcher.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  after removing the cwd from sys.path.\n",
      "c:\\Users\\reece\\anaconda3\\envs\\streetfighter37_copy3\\lib\\site-packages\\ipykernel_launcher.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"\"\"\n",
      "c:\\Users\\reece\\anaconda3\\envs\\streetfighter37_copy3\\lib\\site-packages\\stable_baselines3\\common\\save_util.py:276: UserWarning: Path 'opt\\DQN\\Ken' does not exist. Will create it.\n",
      "  warnings.warn(f\"Path '{path.parent}' does not exist. Will create it.\")\n",
      "[I 2024-04-21 11:03:51,760] Trial 0 finished with value: 1200.0 and parameters: {'learning_rate': 3.5771591936340134e-05, 'gamma': 0.8361070194777762, 'tau': 0.009134398364285881}. Best is trial 0 with value: 1200.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-21 11:05:53,148] Trial 1 finished with value: 200.0 and parameters: {'learning_rate': 2.0066161352259923e-05, 'gamma': 0.8061410267949127, 'tau': 0.0023095538956652197}. Best is trial 0 with value: 1200.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-21 11:07:56,230] Trial 2 finished with value: 0.0 and parameters: {'learning_rate': 2.0382494497267446e-05, 'gamma': 0.896831550203947, 'tau': 0.0021429912634755234}. Best is trial 0 with value: 1200.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-21 11:11:00,224] Trial 3 finished with value: 1100.0 and parameters: {'learning_rate': 4.10387386952234e-05, 'gamma': 0.9655197674607953, 'tau': 0.0014273486547409422}. Best is trial 0 with value: 1200.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-21 11:13:30,777] Trial 4 finished with value: 800.0 and parameters: {'learning_rate': 3.902694701905836e-05, 'gamma': 0.8175603265894009, 'tau': 0.0034150538084659573}. Best is trial 0 with value: 1200.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-21 11:16:06,047] Trial 5 finished with value: 500.0 and parameters: {'learning_rate': 8.511883513709151e-05, 'gamma': 0.8557195005823232, 'tau': 0.0020922811360833227}. Best is trial 0 with value: 1200.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-21 11:18:15,610] Trial 6 finished with value: 600.0 and parameters: {'learning_rate': 9.341908955595047e-05, 'gamma': 0.8619972459533234, 'tau': 0.0020216738547603856}. Best is trial 0 with value: 1200.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-21 11:20:42,487] Trial 7 finished with value: 300.0 and parameters: {'learning_rate': 1.7701352565027112e-05, 'gamma': 0.8393667459992751, 'tau': 0.00406526617535556}. Best is trial 0 with value: 1200.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-21 11:23:42,102] Trial 8 finished with value: 2400.0 and parameters: {'learning_rate': 1.652009725879022e-05, 'gamma': 0.94667260001411, 'tau': 0.006644902426015791}. Best is trial 8 with value: 2400.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-21 11:26:26,407] Trial 9 finished with value: 300.0 and parameters: {'learning_rate': 9.314376079977866e-05, 'gamma': 0.9487648759145528, 'tau': 0.0010100455774978104}. Best is trial 8 with value: 2400.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300.0\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(optimize_agent,n_trials=10,n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenTrial(number=8, state=TrialState.COMPLETE, values=[2400.0], datetime_start=datetime.datetime(2024, 4, 21, 11, 20, 42, 488775), datetime_complete=datetime.datetime(2024, 4, 21, 11, 23, 42, 101316), params={'learning_rate': 1.652009725879022e-05, 'gamma': 0.94667260001411, 'tau': 0.006644902426015791}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'learning_rate': FloatDistribution(high=0.0001, log=True, low=1e-05, step=None), 'gamma': FloatDistribution(high=0.9999, log=True, low=0.8, step=None), 'tau': FloatDistribution(high=0.01, log=True, low=0.001, step=None)}, trial_id=8, value=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 1.652009725879022e-05,\n",
       " 'gamma': 0.94667260001411,\n",
       " 'tau': 0.006644902426015791}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.callbacks import BaseCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainAndLoggingCallback(BaseCallback):\n",
    "    def __init__(self, check_freq, save_path, verbose=1):\n",
    "        super(TrainAndLoggingCallback,self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def _init_callback(self):\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            model_path = os.path.join(self.save_path, 'best_model_{}_'.format(self.n_calls))\n",
    "            self.model.save(model_path)\n",
    "            self.logger.record('matches_won', self.training_env.get_attr('total_matches_won')[0])\n",
    "            self.logger.record('enemy_matches_won', self.training_env.get_attr('total_enemy_matches_won')[0])\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = TrainAndLoggingCallback(check_freq=10000,save_path=CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = StreetFighter()\n",
    "env = Monitor(env,LOG_DIR)\n",
    "env = DummyVecEnv([lambda: env])\n",
    "env = VecFrameStack(env,4,channels_order='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {}\n",
    "model_params['learning_rate'] = 1.652009725879022e-05\n",
    "model_params['gamma'] = 0.94667260001411\n",
    "model_params['tau'] = 0.006644902426015791"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Logging to ./logs/DQN/Ken\\DQN_21\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 7        |\n",
      "| matches_won         | 2        |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 5.21e+03 |\n",
      "|    ep_rew_mean      | 1.22e+04 |\n",
      "|    exploration_rate | 0.802    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 1122     |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 20857    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 14       |\n",
      "| matches_won         | 4        |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 6.05e+03 |\n",
      "|    ep_rew_mean      | 1.18e+04 |\n",
      "|    exploration_rate | 0.54     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 1128     |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 48431    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 22       |\n",
      "| matches_won         | 5        |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 5.56e+03 |\n",
      "|    ep_rew_mean      | 8.59e+03 |\n",
      "|    exploration_rate | 0.366    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 55       |\n",
      "|    time_elapsed     | 1210     |\n",
      "|    total_timesteps  | 66729    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.65e-05 |\n",
      "|    loss             | 1.17     |\n",
      "|    n_updates        | 4182     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 32       |\n",
      "| matches_won         | 5        |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 5.09e+03 |\n",
      "|    ep_rew_mean      | 6.89e+03 |\n",
      "|    exploration_rate | 0.227    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 36       |\n",
      "|    time_elapsed     | 2215     |\n",
      "|    total_timesteps  | 81419    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.65e-05 |\n",
      "|    loss             | 0.387    |\n",
      "|    n_updates        | 7854     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 40       |\n",
      "| matches_won         | 6        |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 5.03e+03 |\n",
      "|    ep_rew_mean      | 6.97e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 28       |\n",
      "|    time_elapsed     | 3536     |\n",
      "|    total_timesteps  | 100678   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.65e-05 |\n",
      "|    loss             | 1.17     |\n",
      "|    n_updates        | 12669    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 45       |\n",
      "| matches_won         | 6        |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4.9e+03  |\n",
      "|    ep_rew_mean      | 6.11e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 24       |\n",
      "|    time_elapsed     | 4751     |\n",
      "|    total_timesteps  | 117576   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.65e-05 |\n",
      "|    loss             | 0.000234 |\n",
      "|    n_updates        | 16893    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 53       |\n",
      "| matches_won         | 7        |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4.91e+03 |\n",
      "|    ep_rew_mean      | 5.98e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 21       |\n",
      "|    time_elapsed     | 6330     |\n",
      "|    total_timesteps  | 137425   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.65e-05 |\n",
      "|    loss             | 0.000307 |\n",
      "|    n_updates        | 21856    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 62       |\n",
      "| matches_won         | 8        |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4.94e+03 |\n",
      "|    ep_rew_mean      | 6.77e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 19       |\n",
      "|    time_elapsed     | 8065     |\n",
      "|    total_timesteps  | 157971   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.65e-05 |\n",
      "|    loss             | 0.000261 |\n",
      "|    n_updates        | 26992    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 71       |\n",
      "| matches_won         | 9        |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4.83e+03 |\n",
      "|    ep_rew_mean      | 6.15e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 18       |\n",
      "|    time_elapsed     | 9180     |\n",
      "|    total_timesteps  | 173805   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.65e-05 |\n",
      "|    loss             | 3.9      |\n",
      "|    n_updates        | 30951    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 78       |\n",
      "| matches_won         | 10       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4.9e+03  |\n",
      "|    ep_rew_mean      | 6.3e+03  |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 18       |\n",
      "|    time_elapsed     | 10717    |\n",
      "|    total_timesteps  | 195822   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.65e-05 |\n",
      "|    loss             | 1.95     |\n",
      "|    n_updates        | 36455    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 88       |\n",
      "| matches_won         | 10       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4.82e+03 |\n",
      "|    ep_rew_mean      | 5.87e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 17       |\n",
      "|    time_elapsed     | 11867    |\n",
      "|    total_timesteps  | 212279   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.65e-05 |\n",
      "|    loss             | 0.00033  |\n",
      "|    n_updates        | 40569    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 96       |\n",
      "| matches_won         | 11       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4.84e+03 |\n",
      "|    ep_rew_mean      | 6.11e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 17       |\n",
      "|    time_elapsed     | 13273    |\n",
      "|    total_timesteps  | 232189   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.65e-05 |\n",
      "|    loss             | 0.000741 |\n",
      "|    n_updates        | 45547    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 105      |\n",
      "| matches_won         | 11       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4.81e+03 |\n",
      "|    ep_rew_mean      | 5.79e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 17       |\n",
      "|    time_elapsed     | 14536    |\n",
      "|    total_timesteps  | 250157   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.65e-05 |\n",
      "|    loss             | 0.00187  |\n",
      "|    n_updates        | 50039    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 112      |\n",
      "| matches_won         | 12       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4.84e+03 |\n",
      "|    ep_rew_mean      | 5.78e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 16       |\n",
      "|    time_elapsed     | 16025    |\n",
      "|    total_timesteps  | 271319   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.65e-05 |\n",
      "|    loss             | 0.388    |\n",
      "|    n_updates        | 55329    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 120      |\n",
      "| matches_won         | 13       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4.87e+03 |\n",
      "|    ep_rew_mean      | 5.84e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 16       |\n",
      "|    time_elapsed     | 17492    |\n",
      "|    total_timesteps  | 292007   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.65e-05 |\n",
      "|    loss             | 0.000529 |\n",
      "|    n_updates        | 60501    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 129      |\n",
      "| matches_won         | 13       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4.85e+03 |\n",
      "|    ep_rew_mean      | 5.56e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 16       |\n",
      "|    time_elapsed     | 18779    |\n",
      "|    total_timesteps  | 310287   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.65e-05 |\n",
      "|    loss             | 0.388    |\n",
      "|    n_updates        | 65071    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 133      |\n",
      "| matches_won         | 13       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4.83e+03 |\n",
      "|    ep_rew_mean      | 5.31e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 16       |\n",
      "|    time_elapsed     | 20050    |\n",
      "|    total_timesteps  | 328193   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.65e-05 |\n",
      "|    loss             | 0.000801 |\n",
      "|    n_updates        | 69548    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 142      |\n",
      "| matches_won         | 13       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4.82e+03 |\n",
      "|    ep_rew_mean      | 5.13e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 16       |\n",
      "|    time_elapsed     | 21404    |\n",
      "|    total_timesteps  | 347326   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.65e-05 |\n",
      "|    loss             | 0.000737 |\n",
      "|    n_updates        | 74331    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 150      |\n",
      "| matches_won         | 13       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4.84e+03 |\n",
      "|    ep_rew_mean      | 5.02e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 16       |\n",
      "|    time_elapsed     | 22878    |\n",
      "|    total_timesteps  | 367894   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.65e-05 |\n",
      "|    loss             | 0.381    |\n",
      "|    n_updates        | 79473    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 158      |\n",
      "| matches_won         | 13       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4.81e+03 |\n",
      "|    ep_rew_mean      | 4.88e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 15       |\n",
      "|    time_elapsed     | 24092    |\n",
      "|    total_timesteps  | 384949   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.65e-05 |\n",
      "|    loss             | 0.00248  |\n",
      "|    n_updates        | 83737    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 168      |\n",
      "| matches_won         | 13       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4.78e+03 |\n",
      "|    ep_rew_mean      | 4.75e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 15       |\n",
      "|    time_elapsed     | 25267    |\n",
      "|    total_timesteps  | 401365   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.65e-05 |\n",
      "|    loss             | 0.372    |\n",
      "|    n_updates        | 87841    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 173      |\n",
      "| matches_won         | 13       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4.74e+03 |\n",
      "|    ep_rew_mean      | 4.61e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 15       |\n",
      "|    time_elapsed     | 26397    |\n",
      "|    total_timesteps  | 417160   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.65e-05 |\n",
      "|    loss             | 0.000913 |\n",
      "|    n_updates        | 91789    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 181      |\n",
      "| matches_won         | 14       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4.75e+03 |\n",
      "|    ep_rew_mean      | 4.82e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 15       |\n",
      "|    time_elapsed     | 27812    |\n",
      "|    total_timesteps  | 436950   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.65e-05 |\n",
      "|    loss             | 0.000483 |\n",
      "|    n_updates        | 96737    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 191      |\n",
      "| matches_won         | 14       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4.73e+03 |\n",
      "|    ep_rew_mean      | 4.68e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 15       |\n",
      "|    time_elapsed     | 29022    |\n",
      "|    total_timesteps  | 453693   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.65e-05 |\n",
      "|    loss             | 0.00114  |\n",
      "|    n_updates        | 100923   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 199      |\n",
      "| matches_won         | 14       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4.73e+03 |\n",
      "|    ep_rew_mean      | 4.58e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 15       |\n",
      "|    time_elapsed     | 30370    |\n",
      "|    total_timesteps  | 472660   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.65e-05 |\n",
      "|    loss             | 1.95     |\n",
      "|    n_updates        | 105664   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 207      |\n",
      "| matches_won         | 15       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4.72e+03 |\n",
      "|    ep_rew_mean      | 4.27e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 15       |\n",
      "|    time_elapsed     | 31830    |\n",
      "|    total_timesteps  | 493031   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.65e-05 |\n",
      "|    loss             | 0.000969 |\n",
      "|    n_updates        | 110757   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 214      |\n",
      "| matches_won         | 17       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4.69e+03 |\n",
      "|    ep_rew_mean      | 4.16e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 15       |\n",
      "|    time_elapsed     | 33582    |\n",
      "|    total_timesteps  | 517458   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.65e-05 |\n",
      "|    loss             | 0.00134  |\n",
      "|    n_updates        | 116864   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 222      |\n",
      "| matches_won         | 18       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4.69e+03 |\n",
      "|    ep_rew_mean      | 4.37e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 15       |\n",
      "|    time_elapsed     | 34920    |\n",
      "|    total_timesteps  | 536144   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.65e-05 |\n",
      "|    loss             | 0.00535  |\n",
      "|    n_updates        | 121535   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 231      |\n",
      "| matches_won         | 18       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4.74e+03 |\n",
      "|    ep_rew_mean      | 4.62e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 15       |\n",
      "|    time_elapsed     | 36335    |\n",
      "|    total_timesteps  | 555756   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.65e-05 |\n",
      "|    loss             | 0.00919  |\n",
      "|    n_updates        | 126438   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 239      |\n",
      "| matches_won         | 19       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4.73e+03 |\n",
      "|    ep_rew_mean      | 4.38e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 15       |\n",
      "|    time_elapsed     | 37596    |\n",
      "|    total_timesteps  | 573524   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.65e-05 |\n",
      "|    loss             | 2.29     |\n",
      "|    n_updates        | 130880   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 247      |\n",
      "| matches_won         | 20       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4.76e+03 |\n",
      "|    ep_rew_mean      | 4.55e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 39806    |\n",
      "|    total_timesteps  | 593725   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.65e-05 |\n",
      "|    loss             | 0.00387  |\n",
      "|    n_updates        | 135931   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 255      |\n",
      "| matches_won         | 21       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4.77e+03 |\n",
      "|    ep_rew_mean      | 4.57e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 41263    |\n",
      "|    total_timesteps  | 614557   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.65e-05 |\n",
      "|    loss             | 0.00101  |\n",
      "|    n_updates        | 141139   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 264      |\n",
      "| matches_won         | 21       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4.74e+03 |\n",
      "|    ep_rew_mean      | 4.17e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 42538    |\n",
      "|    total_timesteps  | 631946   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.65e-05 |\n",
      "|    loss             | 2.02     |\n",
      "|    n_updates        | 145486   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 271      |\n",
      "| matches_won         | 22       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4.79e+03 |\n",
      "|    ep_rew_mean      | 4.36e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 44022    |\n",
      "|    total_timesteps  | 652491   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.65e-05 |\n",
      "|    loss             | 0.00394  |\n",
      "|    n_updates        | 150622   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 278      |\n",
      "| matches_won         | 25       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4.79e+03 |\n",
      "|    ep_rew_mean      | 4.78e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 45661    |\n",
      "|    total_timesteps  | 675010   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.65e-05 |\n",
      "|    loss             | 2.73     |\n",
      "|    n_updates        | 156252   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 287      |\n",
      "| matches_won         | 25       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4.8e+03  |\n",
      "|    ep_rew_mean      | 4.78e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 46961    |\n",
      "|    total_timesteps  | 692768   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.65e-05 |\n",
      "|    loss             | 0.000657 |\n",
      "|    n_updates        | 160691   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 296      |\n",
      "| matches_won         | 26       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4.79e+03 |\n",
      "|    ep_rew_mean      | 4.71e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 48364    |\n",
      "|    total_timesteps  | 711622   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.65e-05 |\n",
      "|    loss             | 3.88     |\n",
      "|    n_updates        | 165405   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 303      |\n",
      "| matches_won         | 27       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4.85e+03 |\n",
      "|    ep_rew_mean      | 5e+03    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 152      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 50083    |\n",
      "|    total_timesteps  | 734804   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.65e-05 |\n",
      "|    loss             | 0.379    |\n",
      "|    n_updates        | 171200   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 313      |\n",
      "| matches_won         | 28       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4.79e+03 |\n",
      "|    ep_rew_mean      | 4.82e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 156      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 51228    |\n",
      "|    total_timesteps  | 750077   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.65e-05 |\n",
      "|    loss             | 0.000589 |\n",
      "|    n_updates        | 175019   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 317      |\n",
      "| matches_won         | 28       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4.78e+03 |\n",
      "|    ep_rew_mean      | 5.08e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 160      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 52698    |\n",
      "|    total_timesteps  | 769868   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.65e-05 |\n",
      "|    loss             | 0.00587  |\n",
      "|    n_updates        | 179966   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 325      |\n",
      "| matches_won         | 29       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4.79e+03 |\n",
      "|    ep_rew_mean      | 5.13e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 164      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 54116    |\n",
      "|    total_timesteps  | 789412   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.65e-05 |\n",
      "|    loss             | 0.00133  |\n",
      "|    n_updates        | 184852   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 335      |\n",
      "| matches_won         | 29       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4.76e+03 |\n",
      "|    ep_rew_mean      | 5.13e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 168      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 55305    |\n",
      "|    total_timesteps  | 804541   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.65e-05 |\n",
      "|    loss             | 3.91     |\n",
      "|    n_updates        | 188635   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 343      |\n",
      "| matches_won         | 30       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4.75e+03 |\n",
      "|    ep_rew_mean      | 5.26e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 172      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 56611    |\n",
      "|    total_timesteps  | 822748   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.65e-05 |\n",
      "|    loss             | 0.39     |\n",
      "|    n_updates        | 193186   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 352      |\n",
      "| matches_won         | 30       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4.73e+03 |\n",
      "|    ep_rew_mean      | 5.2e+03  |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 176      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 58061    |\n",
      "|    total_timesteps  | 841256   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.65e-05 |\n",
      "|    loss             | 5.86     |\n",
      "|    n_updates        | 197813   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 357      |\n",
      "| matches_won         | 30       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4.73e+03 |\n",
      "|    ep_rew_mean      | 5.13e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 180      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 59304    |\n",
      "|    total_timesteps  | 857642   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.65e-05 |\n",
      "|    loss             | 0.00154  |\n",
      "|    n_updates        | 201910   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 366      |\n",
      "| matches_won         | 30       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4.74e+03 |\n",
      "|    ep_rew_mean      | 5.1e+03  |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 184      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 60696    |\n",
      "|    total_timesteps  | 874997   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.65e-05 |\n",
      "|    loss             | 0.000286 |\n",
      "|    n_updates        | 206249   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 376      |\n",
      "| matches_won         | 30       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4.75e+03 |\n",
      "|    ep_rew_mean      | 5.06e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 188      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 61917    |\n",
      "|    total_timesteps  | 891684   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.65e-05 |\n",
      "|    loss             | 0.00041  |\n",
      "|    n_updates        | 210420   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 381      |\n",
      "| matches_won         | 30       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4.71e+03 |\n",
      "|    ep_rew_mean      | 4.71e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 192      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 64017    |\n",
      "|    total_timesteps  | 908100   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.65e-05 |\n",
      "|    loss             | 8.29e-05 |\n",
      "|    n_updates        | 214524   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 390      |\n",
      "| matches_won         | 30       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4.71e+03 |\n",
      "|    ep_rew_mean      | 4.70e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 196      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 65694    |\n",
      "|    total_timesteps  | 924685   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.65e-05 |\n",
      "|    loss             | 1.95     |\n",
      "|    n_updates        | 218671   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 400      |\n",
      "| matches_won         | 30       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4.7e+03  |\n",
      "|    ep_rew_mean      | 4.67e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 200      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 67087    |\n",
      "|    total_timesteps  | 943051   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.65e-05 |\n",
      "|    loss             | 0.000282 |\n",
      "|    n_updates        | 223262   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 408      |\n",
      "| matches_won         | 30       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4.69e+03 |\n",
      "|    ep_rew_mean      | 4.53e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 204      |\n",
      "|    fps              | 14       |\n",
      "|    time_elapsed     | 68549    |\n",
      "|    total_timesteps  | 962012   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.65e-05 |\n",
      "|    loss             | 0.000391 |\n",
      "|    n_updates        | 228002   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 416      |\n",
      "| matches_won         | 30       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4.64e+03 |\n",
      "|    ep_rew_mean      | 4.22e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 208      |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 70792    |\n",
      "|    total_timesteps  | 981186   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.65e-05 |\n",
      "|    loss             | 0.000109 |\n",
      "|    n_updates        | 232796   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| enemy_matches_won   | 421      |\n",
      "| matches_won         | 30       |\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 4.61e+03 |\n",
      "|    ep_rew_mean      | 3.94e+03 |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 212      |\n",
      "|    fps              | 13       |\n",
      "|    time_elapsed     | 72018    |\n",
      "|    total_timesteps  | 997245   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 1.65e-05 |\n",
      "|    loss             | 0.000114 |\n",
      "|    n_updates        | 236811   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.dqn.dqn.DQN at 0x1912b060488>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DQN(\"CnnPolicy\",env,tensorboard_log=LOG_DIR,verbose=2,batch_size=256,buffer_size=80000, **model_params) # cnn policy uses conv neural net for \n",
    "# model.load(os.path.join(OPT_DIR, 'trial_0_best_model.zip'))\n",
    "model.load(os.path.join(OPT_DIR, 'trial_8_best_model.zip'))\n",
    "model.learn(total_timesteps=1000000,callback=callback)\n",
    "# can increase training time and learning rate later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = StreetFighter()\n",
    "env = Monitor(env,LOG_DIR)\n",
    "env = DummyVecEnv([lambda: env])\n",
    "env = VecFrameStack(env,4,channels_order='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3300.0\n"
     ]
    }
   ],
   "source": [
    "model = DQN.load(os.path.join(CHECKPOINT_DIR, 'best_model_500000_'))\n",
    "# best 1000000 - 1400\n",
    "# best 50000 - 3300\n",
    "# model = DQN(\"CnnPolicy\",env,tensorboard_log=LOG_DIR,verbose=2,batch_size=256,buffer_size=80000, **model_params) # cnn policy uses conv neural net for \n",
    "mean_reward, _ = evaluate_policy(model, env, render=True, n_eval_episodes=5)\n",
    "print(mean_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import animation\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_frames_as_gif(frames, path='./', filename='gym_animation.gif'):\n",
    "\n",
    "    #Mess with this to change frame size\n",
    "    plt.figure(figsize=(frames[0].shape[1] / 72.0, frames[0].shape[0] / 72.0), dpi=72)\n",
    "\n",
    "    patch = plt.imshow(frames[0])\n",
    "    plt.axis('off')\n",
    "\n",
    "    def animate(i):\n",
    "        patch.set_data(frames[i])\n",
    "\n",
    "    anim = animation.FuncAnimation(plt.gcf(), animate, frames = len(frames), interval=50)\n",
    "    anim.save(path + filename, writer='imagemagick', fps=180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MovieWriter imagemagick unavailable; using Pillow instead.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANMAAACoCAYAAAB64tvbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAACBElEQVR4nO3ZsQ2EQAwAwb8X/bdsKoCEFQg0kzpxsnLgNTPzAy77P70AfIWYICImiIgJImKCiJggsp0N11p37QGvcfRNcpkgIiaIiAkiYoKImCAiJoiICSJigoiYICImiIgJImKCiJggIiaIiAkiYoKImCAiJoiICSJigoiYICImiIgJImKCiJggIiaIiAkiYoKImCAiJoiICSJigoiYICImiIgJImKCiJggIiaIiAkiYoKImCAiJoiICSJigoiYICImiIgJImKCiJggIiaIiAkiYoKImCAiJoiICSJigoiYICImiIgJImKCiJggIiaIiAkiYoKImCAiJoiICSJigoiYICImiIgJImKCiJggIiaIiAkiYoKImCAiJoiICSJigoiYICImiIgJImKCiJggIiaIiAkiYoKImCAiJoiICSJigoiYICImiIgJImKCiJggIiaIiAkiYoKImCAiJoiICSJigoiYICImiIgJImKCiJggIiaIiAkiYoKImCAiJoiICSJigoiYICImiIgJImKCiJggIiaIiAkiYoKImCAiJoiICSJigoiYICImiIgJImKCiJggIiaIiAkiYoKImCAiJoiICSJigoiYICImiIgJImKCiJggIiaIiAkiYoKImCAiJoiICSJigoiYILKdDWfmrj3g9VwmiIgJImKCiJggIiaIiAkiOy0pC03Pyv2PAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 256x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Ensure you have imagemagick installed with \n",
    "sudo apt-get install imagemagick\n",
    "Open file in CLI with:\n",
    "xgd-open <filelname>\n",
    "\"\"\"\n",
    "\n",
    "#Make gym env\n",
    "my_env = StreetFighter()\n",
    "env = Monitor(my_env,LOG_DIR)\n",
    "env = DummyVecEnv([lambda: env])\n",
    "env = VecFrameStack(env,4,channels_order='last')\n",
    "\n",
    "model = DQN.load(os.path.join(CHECKPOINT_DIR, 'best_model_50000_'))\n",
    "obs = env.reset()\n",
    "done = False\n",
    "frames = []\n",
    "\n",
    "while not done:\n",
    "    if done:\n",
    "        break\n",
    "    # frames.append(env.render(mode=\"rgb_array\"))\n",
    "    env.render()\n",
    "    obs,reward,done,info = env.step(model.predict(obs)[0])\n",
    "    rec_obs = my_env.get_obs_orig()\n",
    "    frames.append(rec_obs)\n",
    "env.close()\n",
    "\n",
    "save_frames_as_gif(frames)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "street_fighter37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
